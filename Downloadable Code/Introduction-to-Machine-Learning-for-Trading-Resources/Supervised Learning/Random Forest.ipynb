{"cells":[{"cell_type":"markdown","metadata":{"id":"H5aXb0BSGuDA"},"source":["# Notebook Instructions\n","\n","1. All the <u>code and data files</u> used in this course are available in the downloadable unit of the <u>last section of this course</u>.\n","2. You can run the notebook document sequentially (one cell at a time) by pressing **Shift + Enter**. \n","3. While a cell is running, a [*] is shown on the left. After the cell is run, the output will appear on the next line.\n","\n","This course is based on specific versions of Python packages. You can find the details of the packages in <a href='https://quantra.quantinsti.com/quantra-notebook' target=\"_blank\" >this manual</a>."]},{"cell_type":"markdown","metadata":{"id":"p3t1mvqVGuDJ"},"source":["# Random Forest\n","Random Forest, also called Random Decision Forest, is a method in machine learning capable of performing both regression and classification tasks. It is a type of ensemble learning that uses multiple learning algorithms for prediction.\n","\n","Random Forest comprises of decision trees, which are graphs of decisions representing their course of action or statistical probability. These multiple trees are plotted to a single tree called the Classification and Regression (CART) Model. To classify an object based on its attributes, each tree gives a classification that is said to vote for that class. The forest then chooses the classification with the maximum number of votes. For regression, it considers the average of the outputs for different trees.\n","\n","<b>Working</b>\n","1. It assumes the number of cases as N. Then, randomly but with replacement, the sample of these N cases is taken out, which will be the training set.\n","2. Considering M to be the input variables, a number m is selected such that m < M. The best split between m and M is used to split the node. The value of m is held constant as the trees are grown.\n","3. Each tree is grown as large as possible.\n","4. By aggregating the predictions of n trees (i.e., majority votes for classification, the average for\n","regression), random forest predicts the new data.\n","\n","\n","![alt text](https://d2a032ejo53cab.cloudfront.net/Glossary/UclBTDKs/image-3.png)\n","\n","For example, in the above diagram, we can observe that each decision tree has voted or predicted a specific class. The final output or class selected by the Random Forest will be the Class N, as it has majority votes or is the predicted output by two out of the four decision trees.\n","\n","\n","\n","Random Forest has certain advantages and disadvantages.\n","\n","<b>Advantages</b>\n","1. This method balances the errors which are present in the dataset.\n","2. It is an effective method because it maintains accuracy even if it has to estimate the missing data.\n","3. Using the out-of-bag error estimate removes the need for a set-aside test set.\n","4. Random Forest helps in unsupervised clustering, data views, and outlier detection.\n","5. It reduces data management time and pre-processing tasks. \n","\n","<b>Disadvantages</b>\n","\n","Disadvantages of the random forest may include its inability to be at par excellence for the regression problem as it does not give precise continuous nature predictions. It cannot predict beyond the range in the\n","training data. Further, it does not provide complete control to the modeller.\n","\n","<b>Applications of Random Forest</b>\n","1. It has many application in computational biology. Doctors can estimate the drug response to a particlar disease using this model.\n","2. This can be used to calculate a person's credit rating by comparing with other persons having similar traits.\n","3. \n","\n","\n","\n","You can learn more about Random Forest and their application in trading in <a href=\"https://blog.quantinsti.com/random-forest-algorithm-in-python/\"> this article</a>. \n","\n","In this notebook, you will perform the following steps:\n","\n","1. [Import Data](#data)\n","\n","\n","2. [Independent Variables](#x)\n","\n","\n","3. [Dependent Variable](#y)\n","\n","\n","4. [Split the Dataset](#split)\n","\n","\n","5. [Train the Model](#model)\n","\n","\n","6. [Accuracy Score](#score)   \n","\n","## Import library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F-KHGVuoGuDN"},"outputs":[],"source":["# For data manipulation\n","import numpy as np\n","import pandas as pd\n","\n","# Import RandomForestClassifier and accuracy_score functions from sklearn\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"4sFn_JF5GuDR"},"source":["<a id='data'></a> \n","\n","## Import Data\n","\n","We will read the daily data of stock, Bank of America, to create features."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXqBKn_hGuDS","outputId":"7834c543-f922-4ae5-f3c1-d66ed8450213"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Adj Close</th>\n","      <th>Volume</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2009-12-31</th>\n","      <td>15.090000</td>\n","      <td>15.240000</td>\n","      <td>15.010000</td>\n","      <td>15.060000</td>\n","      <td>13.114834</td>\n","      <td>94322600</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-04</th>\n","      <td>15.240000</td>\n","      <td>15.750000</td>\n","      <td>15.120000</td>\n","      <td>15.690000</td>\n","      <td>13.663458</td>\n","      <td>180845200</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-05</th>\n","      <td>15.740000</td>\n","      <td>16.209999</td>\n","      <td>15.700000</td>\n","      <td>16.200001</td>\n","      <td>14.107587</td>\n","      <td>209521300</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-06</th>\n","      <td>16.209999</td>\n","      <td>16.540001</td>\n","      <td>16.030001</td>\n","      <td>16.389999</td>\n","      <td>14.273045</td>\n","      <td>205257900</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-07</th>\n","      <td>16.680000</td>\n","      <td>17.190001</td>\n","      <td>16.510000</td>\n","      <td>16.930000</td>\n","      <td>14.743298</td>\n","      <td>320868400</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 Open       High        Low      Close  Adj Close     Volume\n","Date                                                                        \n","2009-12-31  15.090000  15.240000  15.010000  15.060000  13.114834   94322600\n","2010-01-04  15.240000  15.750000  15.120000  15.690000  13.663458  180845200\n","2010-01-05  15.740000  16.209999  15.700000  16.200001  14.107587  209521300\n","2010-01-06  16.209999  16.540001  16.030001  16.389999  14.273045  205257900\n","2010-01-07  16.680000  17.190001  16.510000  16.930000  14.743298  320868400"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# The data is stored in the directory 'data'\n","path = '../data/'\n","\n","# Read stock data from csv file\n","data = pd.read_csv(path + 'BAC_2010_2021.csv', index_col=0)\n","data.index = pd.to_datetime(data.index)\n","data.head()"]},{"cell_type":"markdown","metadata":{"id":"NoDqaMKiGuDU"},"source":["<a id='x'></a> \n","\n","## Independent Variables\n","We will create independent variables which consist of 2 features. The features are:\n","1. Difference of open and close price\n","2. Difference of high and low price"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WDWwrt2sGuDV","outputId":"c7b1c2ea-b30d-49f6-bf5f-7d0e66665809"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open-Close</th>\n","      <th>High-Low</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2009-12-31</th>\n","      <td>0.03</td>\n","      <td>0.23</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-04</th>\n","      <td>-0.45</td>\n","      <td>0.63</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            Open-Close  High-Low\n","Date                            \n","2009-12-31        0.03      0.23\n","2010-01-04       -0.45      0.63"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Create input features\n","data['Open-Close'] = (data['Open'] - data['Close'])\n","data['High-Low'] = (data['High'] - data['Low'])\n","\n","# Drop NaN values\n","data.dropna(inplace=True)\n","\n","# Store the features in a variable X\n","X = data[['Open-Close', 'High-Low']]\n","X.head()"]},{"cell_type":"markdown","metadata":{"id":"YMu9DUXaGuDX"},"source":["<a id='y'></a> \n","\n","## Dependent Variable \n","When the next day's close price is greater than today's close price, we use 1 as a signal and else use -1. We will store this in the variable y, which is the dependent/target variable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4P_hAHngGuDY","outputId":"81d81330-1791-4e6b-aa02-21a6b919a6a8","scrolled":true},"outputs":[{"data":{"text/plain":["array([ 1,  1,  1, ...,  1, -1, -1])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["y = np.where(data['Adj Close'].shift(-1) > data['Adj Close'], 1, -1)\n","y"]},{"cell_type":"markdown","metadata":{"id":"J7lv0jPTGuDa"},"source":["<a id='split'></a> \n","\n","## Split the Dataset\n","We will split the dataset into train and test samples. The train data consists of 75% of the total datasets. On the remaining, we will test the accuracy of the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8f3UR3EZGuDb"},"outputs":[],"source":["# Training dataset length\n","split = int(len(data) * 0.75)\n","\n","# Splitting the X and y into train and test datasets\n","X_train, X_test = X[:split], X[split:]\n","y_train, y_test = y[:split], y[split:]"]},{"cell_type":"markdown","metadata":{"id":"mC2ucAT_GuDc"},"source":["<a id='model'></a> \n","\n","## Train the Model\n","\n","We will use the `RandomForestClassifier` function from sklearn to train and fit the model. The syntax of the followinf function is as follows:\n","```python\n","RandomForestClassifier()\n","```\n","Parameters: \n","\n","    1. random_state (Make it any constant value to produce same results)\n","    \n","    \n","Returns: \n","\n","    1. Predicting the test dataset\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"99cnSo0DGuDc"},"outputs":[],"source":["# Create and fit the model on train dataset\n","clf = RandomForestClassifier(random_state=5)\n","model = clf.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"V8is8qbQGuDd"},"source":["<a id='score'></a> \n","\n","## Accuracy Score\n","The model is trained on the training dataset. Now it's time to test the accuracy of the model on the test dataset. We will use `accuracy_score` function to test the accuracy.The syntax of the followinf function is as follows:\n","```python\n","accuracy_score()\n","```\n","Parameters: \n","\n","    1. y_test\n","    2. Predicted y_test\n","    2. Normalization parameter\n","    \n","    \n","Returns: \n","\n","    1. Prediction accuracy\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1wmDpJ8GuDe","outputId":"44725bff-afa9-4a7a-82d4-734b594517cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Prediction Accuracy (%):  51.41242937853108\n"]}],"source":["print('Prediction Accuracy (%): ', accuracy_score(y_test, model.predict(X_test), normalize=True)*100.0)"]},{"cell_type":"markdown","metadata":{"id":"V6eVjjUHGuDf"},"source":["This is a very simple model with an accuracy of around 51% on the test dataset.\n","##Conclusion\n","In this notebook, we learnt the functioning of the Random Forest Algorithm with the help of an example, along with the Python code to implement this strategy.\n","<br><br>  "]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Random Forest.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
